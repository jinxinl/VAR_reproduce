# 图像生成模型

多模态模型

[TOC]

## 自编码器 `AutoEncoder, AE`  

- 模型架构：

  - 编码器 `Encoder` ：对输入进行编码
  - 解码器 `Decoder` ：使用编码进行重构

  <img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250321111451767.png" alt="image-20250321111451767" style="zoom:60%;" />

- 训练目标：尽可能缩小输入和输入的差距，获得最佳的重构效果
  $$
  (e^*,d^*)=\arg\min_{(e,d)\in E\times D}\epsilon(x,d(e(x)))
  $$
  其中 $e(x)$ 表示对输入 $x$ 进行编码，$d(e(x))$ 表示对编码进行重构。

- 局限：因为模型在隐空间并没有进行任何约束或者正则化，所以无法获得隐空间的有效表示，这意味着难以使用训练好的模型生成全新的图像，只能重构已经有隐空间表征的图像



## 变分自编码器 `Variational AutoEncoder, VAE` 

- > 论文： _Auto-Encoding Variational Bayes_

- 背景：在 `AE` 基础上引入了概率生成模型，往隐空间中引入了概率分布（一般是高斯分布），增加模型生成图片的多样性，同时在训练过程中也能够更好地理解数据分布

- 模型架构：

  - 编码器 `Encoder` ：输入 $x$ 经过编码之后得到一个中间表示，分别经过 `Mean Layer` 和 `Var Layer` 得到均值向量 $\bf m$ 和方差向量 $\bf v$ 
  - 采样 `Sampling` ：使用噪声向量 $\bf e$ ，采样得到 $\bf c=m+e*v$ 
  - 解码器 `Decoder` ：使用采样 $\bf c$ 经过一个 `Up Layer` 生成新的中间表示，然后对这个新的中间表示进行重构，得到最终生成图像

<img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250321112443415.png" alt="image-20250321112443415" style="zoom:67%;" />

- 训练目标：最小化重构损失，同时最小化隐空间的 `KL` 散度，使其接近高斯分布

- `AE` 与 `VAE` 区别：

  |            | AE                                                           | VAE                                                          |
  | :--------: | ------------------------------------------------------------ | ------------------------------------------------------------ |
  |  应用场景  | 降维、压缩、去噪                                             | 生成全新图像，与训练数据相似但不完全一样                     |
  |  基本结构  | Encoder将x映射到Latent Space，Decoder再对Latent Space进行重构 | x经过Encoder得到m和v，采样得到新的Latent Space，Decoder对新的Latent Sapce重构 |
  | 隐空间学习 | Latent Space是确定的，输入x对应一个点，但是未知的，因此无法使用隐空间生成训练数据外的新图像 | 引入概率分布，可以在隐空间采样新的样本，输入x在隐空间上对应一个分布 |
  |  训练目标  | 最小化重构图像和真实图像的差距                               | 最小化重构与真实的差距+最小化隐空间的KL散度                  |

  <img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250321115521935.png" alt="image-20250321115521935" style="zoom:50%;" />

## `Vector Quantised VAE, VQ-VAE` 

- 背景：在 `VAE` 的基础上引入了连续向量离散化技术，将隐层空间的表示从连续向量转化成离散的、可量化的表示，有助于更好地理解数据的离散结构和语义信息，同时防止过拟合
- 模型架构：
  - `Encoder` ：将输入 $x$ 压缩成一个中间表示
  - `VQ` ：使用一个Embedding层 `Codebook` （1）计算每个中间表示与 `Codebook` 的距离（2）计算距离最小的索引（3）根据索引在 `Codebook` 中查找，得到最终的量化后的隐空间表示
  - `Decoder` ：对量化后的向量进行重构

<img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250321121842844.png" alt="image-20250321121842844" style="zoom:67%;" />

- 训练：训练目标是：最小化重构与真实的差距+最小化量化与真实的差距，但是因为模型通过最小距离的索引来计算量化后的表示，而 $\arg\min$ 的计算是不可导的，因此在“最小化量化与真实的差距”的反向传播过程中，会出现不可导的问题，而模型在这里使用了一个小trick。

  模型将量化前后编码的差值看作一个常数，用量化后表示的梯度拷贝到量化前的表示，以此实现连续可导，如下图红色部分所示

  <img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250321122758223.png" alt="image-20250321122758223" style="zoom:67%;" />

- `VQ-VAE` + `PixelCNN` 

  - 背景：虽然 `VQ-VAE` 能够对输入 $x$ 进行压缩、重构，但是无法生成新的图像，例如，随机生成一个输入 $x$ ，通过 `Encoder` 和 `VQ` 后能得到量化后的表示，也能够使用 `Decoder` 进行重构，但是重构的图像中缺失全局信息和局部信息，因为输入 $x$ 的每一个位置都是随机生成的。

    `VQ-VAE` 的作者 `DeepMind` 提出了 `PixelCNN` ，它是一个自回归模型，进行逐像素预测，因为每一个位置的生成都依赖于之前的位置，因此当前状态会包含之前状态的信息，得到的结果中也就能够包含全局信息，生成的图片会考虑到空间信息，更加真实，有助于提高图片的多样性和真实性。

  - 单独使用 `PixelCNN` 也能够生成图像，但是使用 `VQ-VAE` + `PixelCNN` 的效果会更好，因为 `VQ-VAE` 能够起到压缩的效果，提高训练效率，加速收敛。

    例如，对于 $128\times 128\times 3$ 的图片，若是离散空间的大小为 $32\times 32$ ，那么只需要生成 $32\times 32$ 的隐空间表示即可，不用生成 $128\times 128$ 个像素。

  - `PixelCNN` 也能更好地支持有条件和无条件生成

    - 无条件生成：无任何外部条件，输入 $x$ 只是一个随机生成的噪声，通过逐像素生成最终图像
    - 有条件生成：考虑外部条件，外部条件与图片生成有关，比如类别标签、图像部分信息等，作为条件输入 `PixelCNN` ，然后逐像素生成

  - 保证结果的多样性：（1）随机噪声（2）在自回归过程中引入 `top_p` 和 `top_k` 采样



## `VQ-VAE-2`

- 背景：引入了多尺度分层 `Bottom level` 和 `Top level` ，分别是 $64\times 64$ 和 $32\times 32$ ，来进一步增强 `latent code` 上的先验信息，以生成更高分辨率、更高质量的图像
- 模型架构
  - 训练阶段：
    - 编码：首先通过 `Encoder` 层将输入 $x$ 压缩至 `bottom level` 的图像，对应大小 $64\times 64$ ，然后再用 `Encoder` 压缩至 $32\times 32$ 
    - 重建：接着通过 `VQ` 量化得到 `latent code` ，再通过 `Decoder` 层重构为 $64\times 64$ 的压缩图像，接着再经过 `VQ` 量化得到 $64\times 64$ 的 `latent code` ，最后通过 `Decoder` 重建为 $256\times 256$ 的图像
  - 推理阶段：
    - 使用 `PixelCNN` 生成 `Top level` 的 `latent code` ，然后将它作为条件送入 `PixelCNN` ，生成更高分辨率的 `Bottom level` 的离散 `latent code` ，之后将两个level的 `latent code` 通过 `Decoder` 进行重建生成最终图像

<img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250321134529268.png" alt="image-20250321134529268" style="zoom:87%;" />

​	【作者同样还尝试了三个尺度的分层来生成 $1024\times 1024$ 的图像，分别是 $128\times 128$ 、 $64\times 64$ 和 $32\times 32$ 】



## `VQ-GAN` 

- 背景：

  - `VQ-GAN` 是将 `VQ-VAE` 作为生成器，额外引入判别器，对生成图像的质量进行监督
  - 引入感知重建损失，不仅约束像素的差异，还需要约束 `feature map` 的差异，以此重构更具有保真度的图片，学习更丰富的 `Codebook` 
  - 将 `PixelCNN` 换成了更强大的自回归模型 `GPT-2` 
  - 引入滑动窗口机制，降低计算负载

- 模型架构：

  ​	上面是 `Transformer` 部分，下面是 `VQ-GAN` 部分。

  ​	先训练 `VQ-GAN` 部分，再训练 `Transformer` 部分

  <img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250321150905759.png" alt="image-20250321150905759" style="zoom:67%;" />

  - `VQ-GAN` 训练：流程类似 `VQ-VAE` 训练，不同的是加入了判别器，输入 $x$ 通过 `Encoder` 层后得到 `latent code` ，计算其与`Codebook` 的距离，将距离最小的作为索引，在 `Codebook` 中查找，得到量化后的 `latent code` ，最后再通过 `Decoder` 重建，生成图片。

    接下来使用判别器对生成图片逐块检查，每一块会返回 `true` 或 `false` ，并将损失加入总损失中

    还会使用 `VGG` 提取输入和重建图像的多尺度 `feature map` ，监督其对应误差（感知损失 `LIPIS`）

    <img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250321151525479.png" alt="image-20250321151525479" style="zoom:50%;" />

  - `Transformer` 训练：将量化后的 `latent code` 作为输入和标签训练  `Transformer` ，是自回归的监督训练，使用前 $i$ 个位置的code预测第 $i$ 个位置的code，最后学习得到一个 `Codebook` 

    也可以选择有条件约束，条件是和图像有关的信息，比如类别标签等，若是其中包含图像信息，比如图像掩码，需要额外训练一个 `VQ-GAN` 来进行编码。

    以 $16\times 16$ 的 `latent code` 为例，有条件生成时，待生成的 `latent code` 和条件都是 $16\times 16$ 的大小，需要将它们展平，进行拼接，再调用 `Transformer` 进行预测。需要注意的是，传入的向量大小不是 $1\times 512$ 而是 $1\times 511$ ，因为第511个code的预测结果没有对应标签，因此预测生成的code数为511，如果输入512个code，结果反而会更差。

    <img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250321152206737.png" alt="image-20250321152206737" style="zoom:50%;" />

  - 高分辨率生成：若是压缩后的图片大小为 $16\times 16$ （压缩率），最终需要生成 $1024\times 1024$ 分辨率的图片，那么 `latent code` 的大小为 $64\times 64$  在训练 `Transformer` 时，使用 `GPT-2` 代替了 `PixelCNN`，但是 `GPT` 的推理成本与其计算量成平方关系，也就是 $O(64*64*k)$ ，代价较大，因此不提取全局信息，只关注局部信息，使用滑动窗口注意力机制，预测每一个位置的 `code` 时，只考虑局部的 `code` 。

    <img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250321152900094.png" alt="image-20250321152900094" style="zoom:67%;" />



接下来是文生图模型的时代

## DALL-E